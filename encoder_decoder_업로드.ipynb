{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU8Z2xD9ffQo"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9Ks04m19ffQp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ3a7YRxffQq"
      },
      "source": [
        "# Input Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8DGq6CaffQq",
        "outputId": "0594ecb8-8f39-41e9-f03b-0e411785d1dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  5, 34,  7, 45,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "input_sentence = \"I have a dream\"\n",
        "tokenize_input = [\"<sos>\",\"I\", \"have\", \"a\", 'dream', \"<eos>\"]\n",
        "input_idx = [1,5,34,7,45,2]\n",
        "target_idx = [1,5,34,7,45]\n",
        "\n",
        "input_tensor = torch.tensor(input_idx)\n",
        "target_tensor = torch.tensor(target_idx)\n",
        "input_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "to9hGYrXffQr"
      },
      "outputs": [],
      "source": [
        "class Config():\n",
        "    max_position_dim = 20\n",
        "    dim_token_emb = 10\n",
        "    num_dict = 100\n",
        "    num_head = 2\n",
        "    hidden_size = 50\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eXbXbUVfffQr"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embeddings = nn.Embedding(config.num_dict, config.dim_token_emb)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_dim, config.dim_token_emb)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        position_len = input_ids.size(0)\n",
        "        position_ids = torch.arange(position_len, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        word_emb = self.token_embeddings(input_ids)\n",
        "        pos_emb = self.position_embeddings(position_ids)\n",
        "\n",
        "        embeddings = word_emb + pos_emb\n",
        "\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9WOLN-offQs",
        "outputId": "0c30088d-83ec-4cec-f651-c33151c0ea46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "embedding_layer = Embedding(config)\n",
        "emb = embedding_layer(input_tensor)\n",
        "embedded_size=emb.size(2)\n",
        "embedded_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pizdtjn6ffQs"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    dim_k = query.size(-1)\n",
        "    scores = torch.bmm(query, key.transpose(1, 2)) / math.sqrt(dim_k)\n",
        "\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "    weights = F.softmax(scores, dim=-1)\n",
        "\n",
        "    return weights.bmm(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hNoXrsaAffQs"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, embedded_size, head_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.q_linear = nn.Linear(embedded_size, head_dim)\n",
        "        self.k_linear = nn.Linear(embedded_size, head_dim)\n",
        "        self.v_linear = nn.Linear(embedded_size, head_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        q = self.q_linear(x)\n",
        "        k = self.k_linear(x)\n",
        "        v = self.v_linear(x)\n",
        "\n",
        "        self_att_result = scaled_dot_product_attention(q,k,v,mask)\n",
        "\n",
        "        return self_att_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZWnKclHnffQt"
      },
      "outputs": [],
      "source": [
        "class Multi_Attention(nn.Module):\n",
        "    def __init__(self, embedded_size, num_head):\n",
        "        super().__init__()\n",
        "\n",
        "        self.head_dim = int(embedded_size//num_head)\n",
        "        self.heads = nn.ModuleList([Attention(embedded_size, self.head_dim) for _ in range(num_head)])\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        atts = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n",
        "        added_resout = atts + x\n",
        "\n",
        "        normal = nn.BatchNorm1d(added_resout.size(1))\n",
        "        add_norm_result = normal(added_resout)\n",
        "\n",
        "        return add_norm_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ql3toB6pffQt"
      },
      "outputs": [],
      "source": [
        "class TransformEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.multihead = Multi_Attention(config.dim_token_emb, config.num_head)\n",
        "        self.lin1 = nn.Linear(config.dim_token_emb, config.hidden_size)\n",
        "        self.act = nn.GELU()\n",
        "        self.lin2 = nn.Linear(config.hidden_size, config.dim_token_emb)\n",
        "\n",
        "    def forward(self, x):\n",
        "        add_norm_result = self.multihead(x)\n",
        "        fnn_out = self.lin2(self.act(self.lin1(add_norm_result)))\n",
        "        final_feature = fnn_out + add_norm_result\n",
        "        return final_feature\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_vsvn4kffQt",
        "outputId": "1f385b0b-495b-4801-f1c7-fee906d58706"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "encoder = TransformEncoder(config)\n",
        "encoder_emb = encoder(emb)\n",
        "encoder_emb.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0bZTY2rffQu",
        "outputId": "1150b4b4-e1f3-448f-e476-46f5f7142532"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-7.1782e-01,  5.6422e-01,  1.0185e+00,  2.3639e-01, -2.2755e+00,\n",
              "          -9.6843e-01,  2.6404e-01, -8.5887e-01,  1.6938e+00,  2.2063e-01],\n",
              "         [-1.5367e+00, -6.7713e-02,  9.5526e-01, -1.1703e+00,  4.4261e-01,\n",
              "          -1.2672e+00,  1.3898e+00, -1.5787e-01,  1.0250e+00,  1.0717e-01],\n",
              "         [-1.0632e+00,  8.0510e-01, -1.4137e+00,  1.9267e-01, -8.7029e-02,\n",
              "           1.1389e+00,  3.4189e-01,  1.2672e+00,  6.8516e-01, -1.5228e+00],\n",
              "         [-1.8357e+00, -9.3293e-01,  3.2706e-01,  6.7380e-01, -1.5521e+00,\n",
              "          -5.0011e-01,  1.0309e+00,  2.0341e-01,  4.5301e-01,  1.3568e+00],\n",
              "         [ 1.3247e+00,  6.2438e-01, -1.7641e+00, -7.6097e-01,  9.4227e-01,\n",
              "          -7.9003e-01,  1.1809e+00,  9.4054e-01, -6.3874e-01, -2.1180e-01],\n",
              "         [ 1.2781e+00, -9.5282e-02,  1.1536e+00,  6.4716e-02, -8.2029e-02,\n",
              "          -2.4706e+00, -5.2237e-01,  2.3329e-01,  1.1082e-01,  2.0039e-03]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "encoder_emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOSdvTyEffQu"
      },
      "source": [
        "### Do it your-self!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_fobIB8ffQu"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KN9rnMT2ffQu"
      },
      "outputs": [],
      "source": [
        "class Decoder_Attention(nn.Module):\n",
        "    def __init__(self, embedded_size, head_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.q_linear = nn.Linear(embedded_size, head_dim)\n",
        "        self.k_linear = nn.Linear(embedded_size, head_dim)\n",
        "        self.v_linear = nn.Linear(embedded_size, head_dim)\n",
        "\n",
        "    def forward(self, encoder_emb, decoder_emb):\n",
        "        q = self.q_linear(decoder_emb)\n",
        "        k = self.k_linear(encoder_emb)\n",
        "        v = self.v_linear(encoder_emb)\n",
        "\n",
        "        self_att_result = scaled_dot_product_attention(q,k,v)\n",
        "\n",
        "        return self_att_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rz_T-cs5ffQu"
      },
      "outputs": [],
      "source": [
        "class Decoder_Multi_Attention(nn.Module):\n",
        "    def __init__(self, embedded_size, num_head):\n",
        "        super().__init__()\n",
        "\n",
        "        self.head_dim = int(embedded_size//num_head)\n",
        "        self.heads = nn.ModuleList([Decoder_Attention(embedded_size, self.head_dim) for _ in range(num_head)])\n",
        "\n",
        "    def forward(self, encoder_emb, decoder_emb):\n",
        "        atts = torch.cat([h(encoder_emb, decoder_emb) for h in self.heads], dim=-1)\n",
        "        added_resout = atts + decoder_emb\n",
        "\n",
        "        normal = nn.BatchNorm1d(added_resout.size(1))\n",
        "        add_norm_result = normal(added_resout)\n",
        "\n",
        "        return add_norm_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QAMunpp1ffQv"
      },
      "outputs": [],
      "source": [
        "class TransformDecoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.mask_multihead = Multi_Attention(config.dim_token_emb, config.num_head)\n",
        "        self.decoder_multihead = Decoder_Multi_Attention(config.dim_token_emb, config.num_head)\n",
        "\n",
        "        self.lin1 = nn.Linear(config.dim_token_emb, config.hidden_size)\n",
        "        self.act = nn.GELU()\n",
        "        self.lin2 = nn.Linear(config.hidden_size, config.dim_token_emb)\n",
        "\n",
        "\n",
        "    def forward(self, encoder_emb, ouputs_emb, mask):\n",
        "\n",
        "        mask_result = self.mask_multihead(ouputs_emb, mask)\n",
        "\n",
        "        decoder_norm_result = self.decoder_multihead(encoder_emb, mask_result)\n",
        "\n",
        "        fnn_out = self.lin2(self.act(self.lin1(decoder_norm_result)))\n",
        "        final_feature = fnn_out + decoder_norm_result\n",
        "\n",
        "        return final_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ca1d3sl6ffQv"
      },
      "outputs": [],
      "source": [
        "def make_trg_mask( trg):\n",
        "\n",
        "    trg_pad_mask = (trg != 0).unsqueeze(0).unsqueeze(1)\n",
        "    trg_len = trg.size(0)\n",
        "    trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).int()\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "    return trg_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WxG3p_HffQv",
        "outputId": "3599e570-85da-4bb6-9060-1a12eaa5f02e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0912, -0.3218, -0.5308,  1.0944,  0.9801, -0.5948,  1.7363,\n",
              "           0.3040,  0.0286, -2.4114],\n",
              "         [-0.7211, -0.8557, -0.6374,  0.5509, -0.2350,  0.5361,  1.6870,\n",
              "          -0.1681,  0.6900, -2.3676],\n",
              "         [-1.9349,  0.5703,  2.1938,  0.2725, -0.2195, -0.0857,  0.5558,\n",
              "           0.7392, -0.5505, -0.5934],\n",
              "         [-1.2148, -0.7244,  2.0587,  1.0142, -0.4511, -0.2802,  0.8883,\n",
              "          -0.4689, -0.3711, -0.5686],\n",
              "         [-1.4425,  1.5077, -0.7445,  0.9362,  1.3313, -1.9959,  0.2558,\n",
              "           1.6181, -0.6208, -0.1947]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "embedding_layer = Embedding(config)\n",
        "trg_emb = embedding_layer(target_tensor)\n",
        "decoder = TransformDecoder(config)\n",
        "decoder_output = decoder(encoder_emb, trg_emb, make_trg_mask(target_tensor))\n",
        "decoder_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbrI6l6UffQw",
        "outputId": "82fa500e-b78f-4c46-99d4-eeb1deeec135"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "decoder_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWSUCrypffQw"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9v2UNDymffQw"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_layer = Embedding(config)\n",
        "        self.encoder = TransformEncoder(config)\n",
        "        self.decoder = TransformDecoder(config)\n",
        "        self.lin = nn.Linear(config.dim_token_emb, config.dim_token_emb)\n",
        "\n",
        "\n",
        "    def forward(self, source, target):\n",
        "        src_emb = self.embedding_layer(source)\n",
        "        trg_emb = self.embedding_layer(target)\n",
        "\n",
        "        encoder_emb = self.encoder(emb)\n",
        "        decoder_emb = self.decoder(encoder_emb, trg_emb, make_trg_mask(target))\n",
        "        output =  torch.softmax(self.lin(decoder_emb),dim=-1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        trg_pad_mask = (trg != 0).unsqueeze(0).unsqueeze(1)\n",
        "        trg_len = trg.size(0)\n",
        "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).int()\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        return trg_mask\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lMVo0l7qffQw"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NNcavNGffQx",
        "outputId": "61157de1-0eee-48c6-df12-c3daff5d43e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0474, 0.1468, 0.0896, 0.0633, 0.1248, 0.0795, 0.0196, 0.0529,\n",
              "          0.1699, 0.2060],\n",
              "         [0.0598, 0.0592, 0.0764, 0.0705, 0.0693, 0.0879, 0.3266, 0.1419,\n",
              "          0.0411, 0.0673],\n",
              "         [0.0972, 0.0495, 0.0499, 0.0472, 0.0786, 0.1216, 0.2386, 0.1413,\n",
              "          0.0717, 0.1043],\n",
              "         [0.0563, 0.0525, 0.1111, 0.0408, 0.1222, 0.0676, 0.3066, 0.1098,\n",
              "          0.0489, 0.0840],\n",
              "         [0.0630, 0.0997, 0.0903, 0.0733, 0.1625, 0.2256, 0.0476, 0.0661,\n",
              "          0.0568, 0.1152]]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "output = transformer(input_tensor, target_tensor)\n",
        "print(output.shape)\n",
        "output"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}